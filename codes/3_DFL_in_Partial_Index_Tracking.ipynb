{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Code implementation for DFL in partial index tracking**"
      ],
      "metadata": {
        "id": "mD-42CUMnsod"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Install & Import Packages**"
      ],
      "metadata": {
        "id": "DKQacFeZmxXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install packages for CvxpyLayer, Gurobipy\n",
        "\n",
        "!pip install cvxpylayers\n",
        "!pip install gurobipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duv_XMhNxLL5",
        "outputId": "9fe5b77b-7dc7-43a3-c585-7edd12d199be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cvxpylayers in /usr/local/lib/python3.12/dist-packages (0.1.9)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.12/dist-packages (from cvxpylayers) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from cvxpylayers) (1.16.3)\n",
            "Requirement already satisfied: diffcp>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from cvxpylayers) (1.1.4)\n",
            "Requirement already satisfied: cvxpy>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from cvxpylayers) (1.6.7)\n",
            "Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.12/dist-packages (from cvxpy>=1.5.0->cvxpylayers) (1.0.5)\n",
            "Requirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from cvxpy>=1.5.0->cvxpylayers) (0.11.1)\n",
            "Requirement already satisfied: scs>=3.2.4.post1 in /usr/local/lib/python3.12/dist-packages (from cvxpy>=1.5.0->cvxpylayers) (3.2.9)\n",
            "Requirement already satisfied: threadpoolctl>=1.1 in /usr/local/lib/python3.12/dist-packages (from diffcp>=1.1.0->cvxpylayers) (3.6.0)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.12/dist-packages (from clarabel>=0.5.0->cvxpy>=1.5.0->cvxpylayers) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from osqp>=0.6.2->cvxpy>=1.5.0->cvxpylayers) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from osqp>=0.6.2->cvxpy>=1.5.0->cvxpylayers) (75.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from osqp>=0.6.2->cvxpy>=1.5.0->cvxpylayers) (1.5.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi->clarabel>=0.5.0->cvxpy>=1.5.0->cvxpylayers) (2.23)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->osqp>=0.6.2->cvxpy>=1.5.0->cvxpylayers) (3.0.3)\n",
            "Requirement already satisfied: gurobipy in /usr/local/lib/python3.12/dist-packages (13.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cvxpy as cp\n",
        "from tqdm import tqdm\n",
        "from cvxpylayers.torch import CvxpyLayer\n",
        "import argparse\n",
        "import torch\n",
        "import operator\n",
        "from copy import deepcopy\n",
        "import random\n",
        "from functools import reduce\n",
        "import gurobipy as gp"
      ],
      "metadata": {
        "id": "3h_5sTrKgyvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Util functions**"
      ],
      "metadata": {
        "id": "Z0_SEvY_oKzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class View(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, shape):\n",
        "\n",
        "        super().__init__()\n",
        "        self.shape = shape\n",
        "\n",
        "    def __repr__(self):\n",
        "\n",
        "        return f'View{self.shape}'\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        Reshapes the input according to the shape saved in the view data structure.\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size = input.shape[:-1]\n",
        "        shape = (*batch_size, *self.shape)\n",
        "        out = input.view(shape)\n",
        "\n",
        "        return out\n",
        "\n",
        "def dense_nn(\n",
        "    num_features,\n",
        "    num_targets,\n",
        "    num_layers,\n",
        "    intermediate_size=10,\n",
        "    activation='relu',\n",
        "    output_activation='sigmoid',\n",
        "):\n",
        "    \"\"\"\n",
        "    Construct feedforward neural networks\n",
        "    :param num_features: input dimension of networks\n",
        "    :param num_targets: output dimension of networks\n",
        "    :return: Feedforward networks model\n",
        "\n",
        "    \"\"\"\n",
        "    if num_layers > 1:\n",
        "\n",
        "        # The number of nodes\n",
        "        if intermediate_size is None:\n",
        "            intermediate_size = max(num_features, num_targets)\n",
        "\n",
        "        # Activation function\n",
        "        if activation == 'relu':\n",
        "            activation_fn = torch.nn.ReLU\n",
        "        elif activation == 'sigmoid':\n",
        "            activation_fn = torch.nn.Sigmoid\n",
        "        else:\n",
        "            raise Exception('Invalid activation function: ' + str(activation))\n",
        "\n",
        "        # Stack layers\n",
        "        net_layers = [torch.nn.Linear(num_features, intermediate_size), activation_fn()]\n",
        "        for _ in range(num_layers - 2):\n",
        "            net_layers.append(torch.nn.Linear(intermediate_size, intermediate_size))\n",
        "            net_layers.append(activation_fn())\n",
        "        if not isinstance(num_targets, tuple):\n",
        "            net_layers.append(torch.nn.Linear(intermediate_size, num_targets))\n",
        "        else:\n",
        "            net_layers.append(torch.nn.Linear(intermediate_size, reduce(operator.mul, num_targets, 1)))\n",
        "            net_layers.append(View(num_targets))\n",
        "    else:\n",
        "\n",
        "        # Stack layers\n",
        "        if not isinstance(num_targets, tuple):\n",
        "            net_layers = [torch.nn.Linear(num_features, num_targets)]\n",
        "        else:\n",
        "            net_layers = [torch.nn.Linear(num_features, reduce(operator.mul, num_targets, 1)), View(num_targets)]\n",
        "\n",
        "    # Output activation function\n",
        "    if output_activation == 'relu':\n",
        "        net_layers.append(torch.nn.ReLU())\n",
        "    elif output_activation == 'sigmoid':\n",
        "        net_layers.append(torch.nn.Sigmoid())\n",
        "    elif output_activation == 'tanh':\n",
        "        net_layers.append(torch.nn.Tanh())\n",
        "    elif output_activation == 'softmax':\n",
        "        net_layers.append(torch.nn.Softmax(dim=-1))\n",
        "\n",
        "    return torch.nn.Sequential(*net_layers)"
      ],
      "metadata": {
        "id": "WpOrYxOVb0DH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Index tracking problem class**\n",
        "\n",
        "You can download data at the following link:\n",
        "\n",
        "https://github.com/Bridge-PO/ICAIF_25\n",
        "\n",
        "Before running codes, pleas upload Xs.npy, Ys.npy, cap_weights.npy files in folder in Colab Webpage\n",
        "\n",
        "`Data structure`\n",
        "\n",
        "Processed with KOSPI30 from 2015-01-02 ~ 2024-12-30\n",
        "\n",
        "[1] Xs -> [2074 (Total days), 30 (Num stocks), 28 (Num features)]\n",
        "\n",
        "Feature list (Wang et al. 2020)\n",
        "\n",
        "1) Return i days before rebalancing day (i=1,2,3,...,10)\n",
        "\n",
        "2) Cumulative return over the past period j (j= week, month, quarter, year)\n",
        "\n",
        "3) Mean and variance of returns over the past week\n",
        "\n",
        "4) Mean and variance of prices over the past period (3day,week,month,quarter,year)\n",
        "\n",
        "5) Current return\n",
        "\n",
        "6) Current price\n",
        "\n",
        "[2] Ys -> [2074 (Total days), 30 (Num stocks)] -> Cumulative return for next 19 days\n",
        "\n",
        "[3] cap_weight -> [2074 (Total days), 30 (Num stocks)] -> Market cap weight\n",
        "\n",
        "***Reference***\n",
        "\n",
        "Wang, K., Wilder, B., Perrault, A., & Tambe, M. (2020). Automatically learning compact quality-aware surrogates for optimization problems. Advances in Neural Information Processing Systems, 33, 9586-9596."
      ],
      "metadata": {
        "id": "IPoa6oYR3NtL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7QTbQnM5ThK"
      },
      "outputs": [],
      "source": [
        "class IndexTracking():\n",
        "\n",
        "  def __init__(self, n_train, n_test, k):\n",
        "    \"\"\"\n",
        "    Initialize index tracking problem\n",
        "    :param n_train: number of training data\n",
        "    :param n_test: number of test data\n",
        "    :param k: Cardinality k\n",
        "    \"\"\"\n",
        "\n",
        "    # Load data\n",
        "    self.Xs = torch.tensor(np.load('Xs.npy'))\n",
        "    self.Ys = torch.tensor(np.load('Ys.npy'))\n",
        "    self.cap_weights = torch.tensor(np.load('cap_weights.npy'))\n",
        "    self.k = k\n",
        "\n",
        "    # Train, test split\n",
        "    self.n_train = n_train\n",
        "    self.n_test = n_test\n",
        "\n",
        "    idxs = list(range(n_train + n_test))\n",
        "    self.train_idxs = idxs[:self.n_train]\n",
        "    self.test_idxs = idxs[self.n_train:]\n",
        "    self.n_stock = self.Xs.shape[1]\n",
        "\n",
        "  def _load_semi_definite_problem(self):\n",
        "    \"\"\"\n",
        "    Make dictionary of semi-definite index tracking problems\n",
        "    :return: Dictionary of index tracking problems\n",
        "    \"\"\"\n",
        "\n",
        "    prob_dict = []\n",
        "\n",
        "    # Train set\n",
        "    for idx in tqdm(self.train_idxs, desc=\"Train problem generation>>>\"):\n",
        "      cvxpy_prob = self._create_cvxpy_problem(self.cap_weights[idx])\n",
        "      prob_dict.append(cvxpy_prob)\n",
        "\n",
        "    return prob_dict\n",
        "\n",
        "  def _create_cvxpy_problem(self, cap_weight):\n",
        "    \"\"\"\n",
        "    For designated trading day, make cvxpy problem\n",
        "    :param cap_weight: Market cap weight for designated trading day\n",
        "    :return: cvxpy problem\n",
        "    \"\"\"\n",
        "\n",
        "    # Semi-definite relaxation with Cvxpy\n",
        "    W = cp.Variable((self.n_stock, self.n_stock), PSD = True)\n",
        "    R_hat = cp.Parameter((self.n_stock, self.n_stock))\n",
        "    objective = cp.Minimize((cp.trace(R_hat@W)-2*cp.sum(W@R_hat@cap_weight)))\n",
        "    constraints = [cp.sum(W) == 1,\n",
        "                   cp.sum(cp.abs(W)) <= self.k * cp.trace(W),\n",
        "                   W>>0]\n",
        "    problem = cp.Problem(objective, constraints)\n",
        "\n",
        "    return CvxpyLayer(problem, parameters=[R_hat], variables=[W])\n",
        "\n",
        "  def _get_objective(self, Yhats, Y, cap_weight, data_partition=None, data_num=None, loss_type='surrogate'):\n",
        "    \"\"\"\n",
        "    Get decision objective value of index tracking for true Y, prediction Yhats\n",
        "    If loss_type is 'relaxation', solve semi-definite formulation\n",
        "    If loss_type is 'surrogate', solve basic formulation\n",
        "    :param Yhats: Predicted return\n",
        "    :param Y: Asset returns\n",
        "    :param cap_weight: Market cap weight\n",
        "    :param data_partition: 'train', 'val', 'test'\n",
        "    :param data_num: index of data (Only for train and test)\n",
        "    :param loss_type: 'relaxation', 'surrogate'\n",
        "    :return: Objective value\n",
        "    \"\"\"\n",
        "\n",
        "    if loss_type == 'relaxation': # Solve semi-definite formulation\n",
        "\n",
        "      # Make r to R (=rr^T)\n",
        "      Y_sq_hats = torch.outer(Yhats, Yhats)\n",
        "      Y_sq = torch.outer(Y, Y)\n",
        "\n",
        "      problem = self.prob_dict[data_num]\n",
        "      W = problem(Y_sq_hats, solver_args = {'max_iters':int(5e3),'eps_abs':1e-5,'eps_rel':1e-5})[0]\n",
        "\n",
        "      obj = torch.trace(Y_sq@W)-2*torch.sum(W@Y_sq@cap_weight)\n",
        "\n",
        "      return obj\n",
        "\n",
        "    elif loss_type == 'surrogate': # Solve basic formulation\n",
        "\n",
        "      target = (Y @ cap_weight).sum()\n",
        "\n",
        "      w = cp.Variable(Y.shape[0])\n",
        "      z = cp.Variable(Y.shape[0], boolean=True)\n",
        "\n",
        "      # Get optimal portfolio under prediction Yhats\n",
        "      objective = cp.Minimize((w @ Yhats - target) ** 2)\n",
        "      constraints = [cp.sum(w) == 1,\n",
        "                    cp.sum(z) == self.k,\n",
        "                    w <= z,\n",
        "                    w >= -z]\n",
        "      problem = cp.Problem(objective, constraints)\n",
        "      problem.solve(solver='GUROBI')\n",
        "      w_dfl = w.value\n",
        "\n",
        "      # Evaluate obtained portfoilo under true return Y\n",
        "      new_objective = cp.Minimize((w @ Y - target) ** 2)\n",
        "      new_problem = cp.Problem(new_objective, constraints)\n",
        "      new_problem.solve(solver='GUROBI')\n",
        "\n",
        "      # Decision Loss\n",
        "      obj = (w_dfl @ Y.detach().numpy() - target) ** 2 - new_problem.value\n",
        "\n",
        "      return obj\n",
        "\n",
        "  def _loss_fn(self, Yhats, Ys, aux, data_partition, data_num, loss_type):\n",
        "    \"\"\"\n",
        "    Loss function\n",
        "    :param Yhats: Predicted return\n",
        "    :param Ys: Actual return\n",
        "    :param aux: Market cap weight\n",
        "    :param data_partition: 'train', 'val', 'test'\n",
        "    :param data_num: index of data\n",
        "    :param loss_type: 'relaxation', 'surrogate'\n",
        "    :return: Loss value\n",
        "    \"\"\"\n",
        "\n",
        "    dflalpha = 1.0\n",
        "\n",
        "    if loss_type == 'relaxation':\n",
        "      obj = self._get_objective(Yhats, Ys, aux, data_partition, data_num, loss_type)\n",
        "\n",
        "    elif loss_type == 'surrogate':\n",
        "      surrogate_input = torch.cat([Yhats, Ys], dim=-1)\n",
        "      obj = self.surro_model(surrogate_input)\n",
        "\n",
        "    loss = dflalpha * obj + (Yhats - Ys).square().mean()\n",
        "\n",
        "    return loss\n",
        "\n",
        "  def _get_surrogate_loss(self, n_samples):\n",
        "    \"\"\"\n",
        "    Get surrogate loss\n",
        "    :param n_samples: number of samples per Y\n",
        "    :return: Surrogate loss\n",
        "    \"\"\"\n",
        "\n",
        "    # Get data\n",
        "    _, Y_train, Y_train_aux = self.get_train_data()\n",
        "\n",
        "    # Sample Yhats around Y, and accumulate objective value\n",
        "    Y_samples_list = []\n",
        "    Y_trains_list = []\n",
        "    objs_list = []\n",
        "\n",
        "    bar = tqdm(range(Y_train.shape[0]), desc='Generating Samples')\n",
        "    for idx in bar:\n",
        "      y = Y_train[idx]\n",
        "\n",
        "      noise = torch.FloatTensor(n_samples, y.shape[0]).uniform_(-0.1, 0.1)\n",
        "      y_samples = y.unsqueeze(0) + noise\n",
        "\n",
        "      for i in range(n_samples):\n",
        "        y_sample = y_samples[i]\n",
        "        obj = self._get_objective(y_sample,\n",
        "                                  y,\n",
        "                                  Y_train_aux[idx])\n",
        "\n",
        "        Y_samples_list.append(y_sample)\n",
        "        Y_trains_list.append(y)\n",
        "        objs_list.append(obj)\n",
        "\n",
        "    Y_samples = torch.stack(Y_samples_list)\n",
        "    Y_trains = torch.stack(Y_trains_list)\n",
        "    Objs = torch.tensor(objs_list).float().unsqueeze(1)\n",
        "\n",
        "    # Learn Surrogate Model\n",
        "    # Simple Networks Model\n",
        "    def surrogate_nn():\n",
        "\n",
        "      return torch.nn.Sequential(\n",
        "          torch.nn.Linear(Y_samples.shape[1] * 2, 64),\n",
        "          torch.nn.ReLU(),\n",
        "          torch.nn.Linear(64, 64),\n",
        "          torch.nn.ReLU(),\n",
        "          torch.nn.Linear(64, 1),\n",
        "          torch.nn.ReLU()\n",
        "      )\n",
        "\n",
        "    surro_model = surrogate_nn()\n",
        "    optimizer = torch.optim.Adam(surro_model.parameters(), lr=0.001)\n",
        "    mse = torch.nn.MSELoss()\n",
        "\n",
        "    inputs = torch.cat([Y_samples, Y_trains], dim=1)  # [N, 2*dim]\n",
        "\n",
        "    bar = tqdm(range(100))\n",
        "    for epoch in bar:\n",
        "        surro_model.train()\n",
        "        optimizer.zero_grad()\n",
        "        preds = surro_model(inputs)\n",
        "        loss = mse(preds, Objs)\n",
        "        bar.set_description(f'Loss of Surrogate Model: {loss}')\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return surro_model\n",
        "\n",
        "  def get_train_data(self):\n",
        "    \"\"\"\n",
        "    Get train data\n",
        "    :return: Train data\n",
        "    \"\"\"\n",
        "    return self.Xs[self.train_idxs,:self.n_stock,:], self.Ys[self.train_idxs,:self.n_stock], self.cap_weights[self.train_idxs,:self.n_stock]\n",
        "\n",
        "  def get_test_data(self):\n",
        "    \"\"\"\n",
        "    Get test data\n",
        "    :return: Test data\n",
        "    \"\"\"\n",
        "    return self.Xs[self.test_idxs,:self.n_stock,:], self.Ys[self.test_idxs,:self.n_stock], self.cap_weights[self.test_idxs,:self.n_stock]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Load Data**"
      ],
      "metadata": {
        "id": "x1R4rd4DaCis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Argument for indextracking problem\n",
        "problem_kwargs = {'n_train': 50, # Days\n",
        "                  'n_test': 50,  # Days\n",
        "                  'k': 6} # Cardinality\n",
        "\n",
        "problem = IndexTracking(**problem_kwargs)\n",
        "\n",
        "# Get data [day,stock,feature]\n",
        "X_train, Y_train, Y_train_aux = problem.get_train_data()\n",
        "X_test, Y_test, Y_test_aux = problem.get_test_data()"
      ],
      "metadata": {
        "id": "MAffn7ZFtGNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4-1. DFL: Semi-definite Relaxation approach**"
      ],
      "metadata": {
        "id": "RGeJJsxStlSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load semi-definite problems for training\n",
        "problem.prob_dict = problem._load_semi_definite_problem()\n",
        "\n",
        "# Hyperparameters\n",
        "n_layers = 2\n",
        "n_nodes = 10\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load predictive model\n",
        "ipdim, opdim = problem.Xs.shape[-1], 1\n",
        "\n",
        "model_1 = dense_nn(\n",
        "    num_features=ipdim,\n",
        "    num_targets=opdim,\n",
        "    num_layers=n_layers,\n",
        "    intermediate_size=n_nodes,\n",
        "    output_activation='tanh'\n",
        ")\n",
        "optimizer = torch.optim.Adam(model_1.parameters(), lr=learning_rate)\n",
        "\n",
        "# Learning\n",
        "bar = tqdm(range(epochs), desc='Training')\n",
        "for epoch in bar:\n",
        "\n",
        "    losses = []\n",
        "    for i in random.sample(range(len(X_train)), min(batch_size, len(X_train))):\n",
        "        pred = model_1(X_train[i]).squeeze()\n",
        "        losses.append(problem._loss_fn(pred,\n",
        "                                        Y_train[i],\n",
        "                                        aux=Y_train_aux[i],\n",
        "                                        data_partition='train',\n",
        "                                        data_num=i,\n",
        "                                       loss_type='relaxation'))\n",
        "    losses = torch.stack(losses)\n",
        "    loss = losses.nansum()/(len(losses)-losses.isnan().sum())\n",
        "    bar.set_description(f'Loss of Predictive Model : {loss}')\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "XPyCvZXAhqTl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4847b46b-a8df-4fad-bc4a-bcc12aea3007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train problem generation>>>: 100%|██████████| 50/50 [00:12<00:00,  4.02it/s]\n",
            "Loss of Predictive Model : 0.01693020388484001: 100%|██████████| 100/100 [03:29<00:00,  2.09s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4-1. DFL: Surrogate Approach**"
      ],
      "metadata": {
        "id": "CHgtlfWXwy6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Traing surrogate loss model\n",
        "problem.surro_model = problem._get_surrogate_loss(n_samples = 50)\n",
        "\n",
        "# Hyperparameters\n",
        "n_layers = 2\n",
        "n_nodes = 10\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load predictive model\n",
        "ipdim, opdim = problem.Xs.shape[-1], 1\n",
        "\n",
        "model_2 = dense_nn(\n",
        "    num_features=ipdim,\n",
        "    num_targets=opdim,\n",
        "    num_layers=n_layers,\n",
        "    intermediate_size=n_nodes,\n",
        "    output_activation='tanh'\n",
        ")\n",
        "optimizer = torch.optim.Adam(model_2.parameters(), lr=learning_rate)\n",
        "\n",
        "# Learning\n",
        "bar = tqdm(range(epochs), desc='Training')\n",
        "for epoch in bar:\n",
        "\n",
        "    losses = []\n",
        "    for i in random.sample(range(len(X_train)), min(batch_size, len(X_train))):\n",
        "        pred = model_2(X_train[i]).squeeze()\n",
        "        losses.append(problem._loss_fn(pred,\n",
        "                                        Y_train[i],\n",
        "                                        aux=Y_train_aux[i],\n",
        "                                        data_partition='train',\n",
        "                                        data_num=i,\n",
        "                                       loss_type='surrogate'))\n",
        "    losses = torch.stack(losses)\n",
        "    loss = losses.nansum()/(len(losses)-losses.isnan().sum())\n",
        "    bar.set_description(f'Loss of Predictive Model : {loss}')\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXsXvBWnttWp",
        "outputId": "c01a1d8d-43bd-4f74-d170-7ad900187ba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating Samples: 100%|██████████| 50/50 [01:15<00:00,  1.51s/it]\n",
            "Loss of Surrogate Model: 0.00017575877427589148: 100%|██████████| 100/100 [00:00<00:00, 104.73it/s]\n",
            "Loss of Predictive Model : 0.017560550943017006: 100%|██████████| 100/100 [00:04<00:00, 23.62it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Result**"
      ],
      "metadata": {
        "id": "jodkGu1-aa7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Over the test set, you can check mean of decision loss for two kinds of approaches\n",
        "\n",
        "obj1_list = []\n",
        "obj2_list = []\n",
        "\n",
        "bar = tqdm(range(len(X_test)))\n",
        "for i in bar:\n",
        "\n",
        "  pred1 = model_1(X_test[i]).squeeze().detach().numpy()\n",
        "  pred2 = model_2(X_test[i]).squeeze().detach().numpy()\n",
        "\n",
        "  obj1 = problem._get_objective(pred1, Y_test[0], Y_test_aux[0])\n",
        "  obj1_list.append(obj1)\n",
        "\n",
        "  obj2 = problem._get_objective(pred2, Y_test[0], Y_test_aux[0])\n",
        "  obj2_list.append(obj2)\n",
        "\n",
        "  bar.set_description(f'Decision loss of Relaxation Approach : {np.mean(obj1_list)}, Decision loss of Surrogate Approach : {np.mean(obj2_list)}')"
      ],
      "metadata": {
        "id": "3o1zEyyGaeLq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9756025-ca2c-474a-dfad-0dd574c4e31b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Decision loss of Relaxation Approach : 0.04512812942266464, Decision loss of Surrogate Approach : 0.0341593436896801: 100%|██████████| 50/50 [00:03<00:00, 14.25it/s]\n"
          ]
        }
      ]
    }
  ]
}